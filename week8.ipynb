{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVge1/y/FNXrRKa76t+1/4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mendo9988/11jan/blob/main/week8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "egrYvlurAUKS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomDecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        probs = np.bincount(y) / len(y)\n",
        "        return -np.sum(probs * np.log2(probs + 1e-9))\n",
        "\n",
        "    def _information_gain(self, parent, left, right):\n",
        "        weight_l = len(left) / len(parent)\n",
        "        weight_r = len(right) / len(parent)\n",
        "        return self._entropy(parent) - (weight_l * self._entropy(left) + weight_r * self._entropy(right))\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        if len(np.unique(y)) == 1 or (self.max_depth and depth >= self.max_depth):\n",
        "            return {'class': np.bincount(y).argmax()}\n",
        "\n",
        "        best_gain = -1\n",
        "        best_split = None\n",
        "\n",
        "        for feature in range(X.shape[1]):\n",
        "            for threshold in np.unique(X[:, feature]):\n",
        "                left = y[X[:, feature] <= threshold]\n",
        "                right = y[X[:, feature] > threshold]\n",
        "                if len(left) == 0 or len(right) == 0:\n",
        "                    continue\n",
        "                gain = self._information_gain(y, left, right)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_split = (feature, threshold)\n",
        "\n",
        "        if best_split is None:\n",
        "            return {'class': np.bincount(y).argmax()}\n",
        "\n",
        "        feature, threshold = best_split\n",
        "        left_mask = X[:, feature] <= threshold\n",
        "        right_mask = ~left_mask\n",
        "\n",
        "        return {\n",
        "            'feature': feature,\n",
        "            'threshold': threshold,\n",
        "            'left': self._build_tree(X[left_mask], y[left_mask], depth+1),\n",
        "            'right': self._build_tree(X[right_mask], y[right_mask], depth+1)\n",
        "        }\n",
        "\n",
        "    def _predict_one(self, x, tree):\n",
        "        if 'class' in tree:\n",
        "            return tree['class']\n",
        "        if x[tree['feature']] <= tree['threshold']:\n",
        "            return self._predict_one(x, tree['left'])\n",
        "        return self._predict_one(x, tree['right'])\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self._predict_one(x, self.tree) for x in X]\n"
      ],
      "metadata": {
        "id": "GRvihE6bo5xl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "eNrftcVVo9Em"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "custom_tree = CustomDecisionTree(max_depth=3)\n",
        "custom_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_custom = custom_tree.predict(X_test)\n",
        "print(\"Custom Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_custom))\n"
      ],
      "metadata": {
        "id": "pnxwMSXKo-Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sk_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "sk_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_sk = sk_tree.predict(X_test)\n",
        "print(\"Scikit-learn Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_sk))\n"
      ],
      "metadata": {
        "id": "S73hny88pAr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "dt_f1 = f1_score(y_test, dt.predict(X_test), average='weighted')\n",
        "rf_f1 = f1_score(y_test, rf.predict(X_test), average='weighted')\n",
        "\n",
        "print(\"Decision Tree F1 Score:\", dt_f1)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)\n"
      ],
      "metadata": {
        "id": "DJmg0V7jpEam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(RandomForestClassifier(random_state=42),\n",
        "                    param_grid,\n",
        "                    scoring='f1_weighted',\n",
        "                    cv=5)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best F1 Score:\", grid.best_score_)\n"
      ],
      "metadata": {
        "id": "iUkb6B4YpHl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X, y = wine.data, wine.target.astype(float)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "rf_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "dt_reg.fit(X_train, y_train)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "print(\"DT MSE:\", mean_squared_error(y_test, dt_reg.predict(X_test)))\n",
        "print(\"RF MSE:\", mean_squared_error(y_test, rf_reg.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "IYE4k6DwpKDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=5,\n",
        "    cv=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Score:\", random_search.best_score_)\n"
      ],
      "metadata": {
        "id": "SussJ61fp8ZD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}